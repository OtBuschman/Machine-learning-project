{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8926a782",
   "metadata": {},
   "source": [
    "# Pipeline 2: Advanced Feature Engineering and Preprocessing\n",
    "\n",
    "This notebook implements a second preprocessing pipeline that focuses on:\n",
    "1. **Feature Engineering**: Creating new meaningful features from existing ones\n",
    "2. **Advanced Scaling**: Using RobustScaler and QuantileTransformer for better handling of outliers\n",
    "3. **Target Encoding**: Using TargetEncoder for high-cardinality categorical features\n",
    "4. **Advanced Imputation**: Using IterativeImputer for sophisticated missing value handling\n",
    "5. **Feature Selection**: Reducing dimensionality while preserving important information\n",
    "\n",
    "## Motivation\n",
    "\n",
    "This pipeline differs from a basic approach by:\n",
    "- Creating domain-specific features that capture relationships between variables\n",
    "- Using more robust scaling methods that handle outliers better\n",
    "- Leveraging target information for categorical encoding\n",
    "- Implementing sophisticated missing value imputation\n",
    "- Reducing feature space through intelligent selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf84573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Enable experimental features FIRST\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore data\n",
    "data = pd.read_csv('health_insurance_train.csv')\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())\n",
    "print(\"\\nData types:\")\n",
    "print(data.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\nTarget variable (whrswk) statistics:\")\n",
    "print(data['whrswk'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.drop('whrswk', axis=1)\n",
    "y = data['whrswk']\n",
    "\n",
    "# Identify feature types\n",
    "categorical_features = ['hhi', 'whi', 'hhi2', 'education', 'race', 'hispanic', 'region']\n",
    "numerical_features = ['experience', 'kidslt6', 'kids618', 'husby']\n",
    "\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"Numerical features:\", numerical_features)\n",
    "print(\"\\nCategorical feature value counts:\")\n",
    "for col in categorical_features:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(X[col].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Functions\n",
    "def create_engineered_features(X):\n",
    "    \"\"\"\n",
    "    Create new features based on domain knowledge and relationships between variables\n",
    "    \"\"\"\n",
    "    X_eng = X.copy()\n",
    "    \n",
    "    # 1. Family structure features\n",
    "    X_eng['total_kids'] = X_eng['kidslt6'] + X_eng['kids618']\n",
    "    X_eng['has_kids'] = (X_eng['total_kids'] > 0).astype(int)\n",
    "    X_eng['has_young_kids'] = (X_eng['kidslt6'] > 0).astype(int)\n",
    "    \n",
    "    # 2. Work-life balance indicators\n",
    "    X_eng['husby_per_kid'] = X_eng['husby'] / (X_eng['total_kids'] + 1)  # +1 to avoid division by zero\n",
    "    X_eng['experience_per_kid'] = X_eng['experience'] / (X_eng['total_kids'] + 1)\n",
    "    \n",
    "    # 3. Insurance coverage combinations\n",
    "    X_eng['insurance_coverage'] = (\n",
    "        (X_eng['hhi'] == 'yes').astype(int) + \n",
    "        (X_eng['whi'] == 'yes').astype(int) + \n",
    "        (X_eng['hhi2'] == 'yes').astype(int)\n",
    "    )\n",
    "    \n",
    "    # 4. Education level encoding (ordinal)\n",
    "    education_mapping = {\n",
    "        '9-11years': 1,\n",
    "        '12years': 2, \n",
    "        '13-15years': 3,\n",
    "        '16years': 4,\n",
    "        '>16years': 5\n",
    "    }\n",
    "    X_eng['education_encoded'] = X_eng['education'].map(education_mapping)\n",
    "    \n",
    "    # 5. Regional economic indicators (based on common knowledge)\n",
    "    region_economic = {\n",
    "        'northeast': 4,  # Generally higher income\n",
    "        'northcentral': 3,\n",
    "        'south': 2,      # Generally lower income\n",
    "        'west': 3,\n",
    "        'other': 2\n",
    "    }\n",
    "    X_eng['region_economic'] = X_eng['region'].map(region_economic)\n",
    "    \n",
    "    # 6. Experience categories\n",
    "    X_eng['experience_category'] = pd.cut(\n",
    "        X_eng['experience'], \n",
    "        bins=[0, 5, 15, 25, 100], \n",
    "        labels=['entry', 'mid', 'senior', 'expert']\n",
    "    )\n",
    "    \n",
    "    # 7. Interaction features\n",
    "    X_eng['experience_education'] = X_eng['experience'] * X_eng['education_encoded']\n",
    "    X_eng['husby_education'] = X_eng['husby'] * X_eng['education_encoded']\n",
    "    \n",
    "    return X_eng\n",
    "\n",
    "# Apply feature engineering\n",
    "X_engineered = create_engineered_features(X)\n",
    "print(\"Original features:\", X.shape[1])\n",
    "print(\"Engineered features:\", X_engineered.shape[1])\n",
    "print(\"\\nNew features created:\")\n",
    "new_features = [col for col in X_engineered.columns if col not in X.columns]\n",
    "print(new_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b51268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update feature lists after engineering\n",
    "categorical_features_eng = ['hhi', 'whi', 'hhi2', 'education', 'race', 'hispanic', 'region', 'experience_category']\n",
    "numerical_features_eng = ['experience', 'kidslt6', 'kids618', 'husby', 'total_kids', 'has_kids', 'has_young_kids',\n",
    "                         'husby_per_kid', 'experience_per_kid', 'insurance_coverage', 'education_encoded',\n",
    "                         'region_economic', 'experience_education', 'husby_education']\n",
    "\n",
    "print(\"Updated categorical features:\", categorical_features_eng)\n",
    "print(\"Updated numerical features:\", numerical_features_eng)\n",
    "print(f\"Total features: {len(categorical_features_eng) + len(numerical_features_eng)}\")\n",
    "\n",
    "# Check for any missing values in engineered features\n",
    "print(\"\\nMissing values in engineered features:\")\n",
    "print(X_engineered[numerical_features_eng].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9386449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the advanced preprocessing pipeline\n",
    "def create_advanced_pipeline():\n",
    "    \"\"\"\n",
    "    Create an advanced preprocessing pipeline with:\n",
    "    - IterativeImputer for sophisticated missing value handling\n",
    "    - OneHotEncoder for categorical features (TargetEncoder doesn't work with multiclass targets)\n",
    "    - RobustScaler for numerical features (robust to outliers)\n",
    "    - QuantileTransformer for non-linear transformation\n",
    "    - Feature selection to reduce dimensionality\n",
    "    \"\"\"\n",
    "    \n",
    "    # Numerical preprocessing pipeline\n",
    "    numerical_pipeline = Pipeline([\n",
    "        ('imputer', IterativeImputer(random_state=RANDOM_STATE, max_iter=10)),\n",
    "        ('scaler', RobustScaler()),  # More robust to outliers than StandardScaler\n",
    "        ('quantile', QuantileTransformer(output_distribution='normal', random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    \n",
    "    # Categorical preprocessing pipeline\n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    # Combine preprocessing for different feature types\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numerical_pipeline, numerical_features_eng),\n",
    "        ('cat', categorical_pipeline, categorical_features_eng)\n",
    "    ])\n",
    "    \n",
    "    # Full pipeline with feature selection\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature_selection', SelectKBest(score_func=mutual_info_regression, k=15)),  # Select top 15 features\n",
    "        ('regressor', RandomForestRegressor(random_state=RANDOM_STATE, n_estimators=100))\n",
    "    ])\n",
    "    \n",
    "    return full_pipeline\n",
    "\n",
    "# Create the pipeline\n",
    "advanced_pipeline = create_advanced_pipeline()\n",
    "print(\"Advanced pipeline created successfully!\")\n",
    "print(\"Pipeline steps:\")\n",
    "for i, (name, step) in enumerate(advanced_pipeline.steps):\n",
    "    print(f\"{i+1}. {name}: {step}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_engineered, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# Train the advanced pipeline\n",
    "print(\"\\nTraining advanced pipeline...\")\n",
    "advanced_pipeline.fit(X_train, y_train)\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_advanced = advanced_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_advanced = mean_absolute_error(y_test, y_pred_advanced)\n",
    "mse_advanced = mean_squared_error(y_test, y_pred_advanced)\n",
    "r2_advanced = r2_score(y_test, y_pred_advanced)\n",
    "\n",
    "print(f\"\\nAdvanced Pipeline Performance:\")\n",
    "print(f\"MAE: {mae_advanced:.4f}\")\n",
    "print(f\"MSE: {mse_advanced:.4f}\")\n",
    "print(f\"R¬≤: {r2_advanced:.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mse_advanced):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5060b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with dummy regressor (baseline)\n",
    "# DummyRegressor provides a simple sanity check by comparing against simple rules of thumb\n",
    "# For regression, we use 'mean' strategy which always predicts the mean of training targets\n",
    "# This helps us understand if our model is actually learning meaningful patterns\n",
    "\n",
    "dummy_regressor = DummyRegressor(strategy='mean')\n",
    "dummy_regressor.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy_regressor.predict(X_test)\n",
    "\n",
    "mae_dummy = mean_absolute_error(y_test, y_pred_dummy)\n",
    "mse_dummy = mean_squared_error(y_test, y_pred_dummy)\n",
    "r2_dummy = r2_score(y_test, y_pred_dummy)\n",
    "\n",
    "print(f\"\\nDummy Regressor (Baseline) Performance:\")\n",
    "print(f\"MAE: {mae_dummy:.4f}\")\n",
    "print(f\"MSE: {mse_dummy:.4f}\")\n",
    "print(f\"R¬≤: {r2_dummy:.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mse_dummy):.4f}\")\n",
    "\n",
    "print(f\"\\nImprovement over baseline:\")\n",
    "print(f\"MAE improvement: {((mae_dummy - mae_advanced) / mae_dummy * 100):.2f}%\")\n",
    "print(f\"R¬≤ improvement: {((r2_advanced - r2_dummy) / abs(r2_dummy) * 100):.2f}%\")\n",
    "\n",
    "# If our model performs worse than dummy regressor, something is wrong!\n",
    "if mae_advanced > mae_dummy:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Model performs worse than dummy regressor!\")\n",
    "    print(\"This suggests the model is not learning meaningful patterns.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Model performs better than dummy regressor - good sign!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f1fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation to get more robust performance estimate\n",
    "print(\"Performing cross-validation...\")\n",
    "cv_scores = cross_val_score(advanced_pipeline, X_engineered, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "cv_mae = -cv_scores.mean()\n",
    "cv_std = cv_scores.std()\n",
    "\n",
    "print(f\"Cross-validation MAE: {cv_mae:.4f} (+/- {cv_std * 2:.4f})\")\n",
    "print(f\"Individual CV scores: {[-score for score in cv_scores]}\")\n",
    "\n",
    "# This is our estimate for the autograder\n",
    "print(f\"\\nEstimated MAE on new data: {cv_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning with GridSearchCV\n",
    "# Following the tips: systematic hyperparameter search with proper parameter ranges\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "import time\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "print(\"This may take a while due to the comprehensive search...\")\n",
    "\n",
    "# Define parameter grids for each model\n",
    "# Using logarithmic scales for parameters that can vary widely (as recommended in tips)\n",
    "param_grids = {\n",
    "    'KNN': {\n",
    "        'regressor__n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "        'regressor__weights': ['uniform', 'distance'],\n",
    "        'regressor__p': [1, 2]  # Manhattan vs Euclidean distance\n",
    "    },\n",
    "    'SGD': {\n",
    "        'regressor__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        'regressor__learning_rate': ['constant', 'optimal', 'invscaling'],\n",
    "        'regressor__eta0': [0.01, 0.1, 1.0],\n",
    "        'regressor__max_iter': [1000, 2000, 5000]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'regressor__n_estimators': [50, 100, 200],\n",
    "        'regressor__max_depth': [None, 10, 20, 30],\n",
    "        'regressor__min_samples_split': [2, 5, 10],\n",
    "        'regressor__min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'regressor__max_depth': [None, 5, 10, 15, 20],\n",
    "        'regressor__min_samples_split': [2, 5, 10, 20],\n",
    "        'regressor__min_samples_leaf': [1, 2, 4, 8],\n",
    "        'regressor__criterion': ['squared_error', 'friedman_mse']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Store results\n",
    "tuned_models = {}\n",
    "tuning_results = {}\n",
    "\n",
    "print(\"\\nTuning models individually...\")\n",
    "for name, param_grid in param_grids.items():\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create base model\n",
    "    if name == 'KNN':\n",
    "        base_model = KNeighborsRegressor()\n",
    "    elif name == 'SGD':\n",
    "        base_model = SGDRegressor(random_state=RANDOM_STATE, early_stopping=True)\n",
    "    elif name == 'Random Forest':\n",
    "        base_model = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "    elif name == 'Decision Tree':\n",
    "        base_model = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Create pipeline with the model\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', advanced_pipeline.named_steps['preprocessor']),\n",
    "        ('feature_selection', advanced_pipeline.named_steps['feature_selection']),\n",
    "        ('regressor', base_model)\n",
    "    ])\n",
    "    \n",
    "    # Grid search with 3-fold CV for speed (5-fold would be better but slower)\n",
    "    grid_search = GridSearchCV(\n",
    "        model_pipeline, \n",
    "        param_grid, \n",
    "        cv=3, \n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Store results\n",
    "    tuned_models[name] = grid_search.best_estimator_\n",
    "    tuning_results[name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': -grid_search.best_score_,  # Convert back to positive MAE\n",
    "        'tuning_time': time.time() - start_time\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} tuning completed in {tuning_results[name]['tuning_time']:.2f} seconds\")\n",
    "    print(f\"Best MAE: {tuning_results[name]['best_score']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "for name, results in tuning_results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Best MAE: {results['best_score']:.4f}\")\n",
    "    print(f\"  Tuning time: {results['tuning_time']:.2f}s\")\n",
    "    print(f\"  Best parameters: {results['best_params']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6758a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tuned models on test set\n",
    "print(\"Evaluating tuned models on test set...\")\n",
    "tuned_test_results = {}\n",
    "\n",
    "for name, model in tuned_models.items():\n",
    "    # Make predictions\n",
    "    y_pred_tuned = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae_tuned = mean_absolute_error(y_test, y_pred_tuned)\n",
    "    mse_tuned = mean_squared_error(y_test, y_pred_tuned)\n",
    "    r2_tuned = r2_score(y_test, y_pred_tuned)\n",
    "    \n",
    "    tuned_test_results[name] = {\n",
    "        'MAE': mae_tuned,\n",
    "        'MSE': mse_tuned,\n",
    "        'R2': r2_tuned,\n",
    "        'RMSE': np.sqrt(mse_tuned)\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} - MAE: {mae_tuned:.4f}, R¬≤: {r2_tuned:.4f}\")\n",
    "\n",
    "# Compare before and after tuning\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE COMPARISON: BEFORE vs AFTER TUNING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<15} | {'Before MAE':<12} | {'After MAE':<12} | {'Improvement':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Get original performance for comparison\n",
    "original_mae = mae_advanced  # From the advanced pipeline\n",
    "print(f\"{'Advanced Pipeline':<15} | {original_mae:<12.4f} | {mae_advanced:<12.4f} | {'Baseline':<12}\")\n",
    "\n",
    "for name, results in tuned_test_results.items():\n",
    "    # For comparison, we'll use the original advanced pipeline as baseline\n",
    "    improvement = ((original_mae - results['MAE']) / original_mae * 100)\n",
    "    print(f\"{name:<15} | {original_mae:<12.4f} | {results['MAE']:<12.4f} | {improvement:>+10.2f}%\")\n",
    "\n",
    "# Find best tuned model\n",
    "best_tuned_model = min(tuned_test_results.keys(), key=lambda x: tuned_test_results[x]['MAE'])\n",
    "best_tuned_mae = tuned_test_results[best_tuned_model]['MAE']\n",
    "\n",
    "print(f\"\\nüèÜ Best tuned model: {best_tuned_model}\")\n",
    "print(f\"Best tuned MAE: {best_tuned_mae:.4f}\")\n",
    "\n",
    "if best_tuned_mae < original_mae:\n",
    "    improvement = ((original_mae - best_tuned_mae) / original_mae * 100)\n",
    "    print(f\"‚úÖ Hyperparameter tuning improved performance by {improvement:.2f}%\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Hyperparameter tuning did not improve performance\")\n",
    "    print(\"This can happen if the original parameters were already good or if we need more data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1999f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Curves and Convergence Analysis\n",
    "# Following the tips: visualize SGD convergence and learning curves\n",
    "\n",
    "print(\"Creating training curves and convergence analysis...\")\n",
    "\n",
    "# 1. SGD Convergence Analysis\n",
    "print(\"\\n1. SGD Convergence Analysis\")\n",
    "sgd_model = tuned_models['SGD']\n",
    "sgd_regressor = sgd_model.named_steps['regressor']\n",
    "\n",
    "# Get the loss curve from SGD (if available)\n",
    "if hasattr(sgd_regressor, 'loss_curve_'):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(sgd_regressor.loss_curve_)\n",
    "    plt.title('SGD Loss Curve')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show convergence\n",
    "    plt.subplot(1, 2, 2)\n",
    "    # Take last 20% of epochs to show convergence\n",
    "    start_idx = int(len(sgd_regressor.loss_curve_) * 0.8)\n",
    "    plt.plot(sgd_regressor.loss_curve_[start_idx:])\n",
    "    plt.title('SGD Convergence (Last 20% of Epochs)')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"SGD converged after {len(sgd_regressor.loss_curve_)} epochs\")\n",
    "    print(f\"Final loss: {sgd_regressor.loss_curve_[-1]:.6f}\")\n",
    "else:\n",
    "    print(\"SGD loss curve not available (early_stopping might be enabled)\")\n",
    "\n",
    "# 2. Learning Curves for all models\n",
    "print(\"\\n2. Learning Curves Analysis\")\n",
    "\n",
    "def plot_learning_curve(model, X, y, title, cv=3):\n",
    "    \"\"\"Plot learning curve for a given model\"\"\"\n",
    "    train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "    train_sizes_abs = (train_sizes * len(X)).astype(int)\n",
    "    \n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    \n",
    "    for size in train_sizes_abs:\n",
    "        # Sample data\n",
    "        indices = np.random.choice(len(X), size, replace=False)\n",
    "        X_sample = X.iloc[indices] if hasattr(X, 'iloc') else X[indices]\n",
    "        y_sample = y.iloc[indices] if hasattr(y, 'iloc') else y[indices]\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_sample, y_sample, cv=min(cv, size//10), \n",
    "                                  scoring='neg_mean_absolute_error')\n",
    "        val_scores.append(-cv_scores.mean())\n",
    "        \n",
    "        # Training score\n",
    "        model.fit(X_sample, y_sample)\n",
    "        train_pred = model.predict(X_sample)\n",
    "        train_mae = mean_absolute_error(y_sample, train_pred)\n",
    "        train_scores.append(train_mae)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes_abs, train_scores, 'o-', label='Training MAE', color='blue')\n",
    "    plt.plot(train_sizes_abs, val_scores, 'o-', label='Validation MAE', color='red')\n",
    "    plt.title(f'Learning Curve - {title}')\n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return train_scores, val_scores\n",
    "\n",
    "# Plot learning curves for best models\n",
    "print(\"Plotting learning curves for best models...\")\n",
    "\n",
    "# Use a subset of data for learning curves (to speed up computation)\n",
    "X_sample = X_engineered.sample(n=min(2000, len(X_engineered)), random_state=RANDOM_STATE)\n",
    "y_sample = y[X_sample.index]\n",
    "\n",
    "# Plot for best tuned model\n",
    "best_model = tuned_models[best_tuned_model]\n",
    "plot_learning_curve(best_model, X_sample, y_sample, f'Best Model ({best_tuned_model})')\n",
    "\n",
    "# Plot for Random Forest (usually shows clear learning curve)\n",
    "if 'Random Forest' in tuned_models:\n",
    "    plot_learning_curve(tuned_models['Random Forest'], X_sample, y_sample, 'Random Forest')\n",
    "\n",
    "print(\"Learning curves completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update final model selection and autograder submission\n",
    "print(\"Updating final model selection based on tuning results...\")\n",
    "\n",
    "# Select the best model (either original advanced pipeline or best tuned model)\n",
    "if best_tuned_mae < mae_advanced:\n",
    "    final_model = tuned_models[best_tuned_model]\n",
    "    final_mae_estimate = best_tuned_mae\n",
    "    model_type = f\"Tuned {best_tuned_model}\"\n",
    "    print(f\"‚úÖ Using tuned {best_tuned_model} as final model\")\n",
    "else:\n",
    "    final_model = advanced_pipeline\n",
    "    final_mae_estimate = mae_advanced\n",
    "    model_type = \"Advanced Pipeline (Random Forest)\"\n",
    "    print(f\"‚úÖ Using original advanced pipeline as final model\")\n",
    "\n",
    "# Retrain on full dataset\n",
    "print(f\"\\nRetraining {model_type} on full dataset...\")\n",
    "final_model.fit(X_engineered, y)\n",
    "\n",
    "# Update cross-validation estimate\n",
    "print(\"Performing final cross-validation...\")\n",
    "final_cv_scores = cross_val_score(final_model, X_engineered, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "final_cv_mae = -final_cv_scores.mean()\n",
    "final_cv_std = final_cv_scores.std()\n",
    "\n",
    "print(f\"Final CV MAE: {final_cv_mae:.4f} (+/- {final_cv_std * 2:.4f})\")\n",
    "print(f\"Individual CV scores: {[-score for score in final_cv_scores]}\")\n",
    "\n",
    "# This is our final estimate for the autograder\n",
    "print(f\"\\nFinal estimated MAE on new data: {final_cv_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autograder data and make predictions\n",
    "print(\"Loading autograder data...\")\n",
    "data_autograder = pd.read_csv('health_insurance_autograde.csv')\n",
    "print(f\"Autograder data shape: {data_autograder.shape}\")\n",
    "\n",
    "# Apply the same feature engineering to autograder data\n",
    "X_autograder_eng = create_engineered_features(data_autograder)\n",
    "print(f\"Engineered autograder data shape: {X_autograder_eng.shape}\")\n",
    "\n",
    "# Make predictions on autograder data using final model\n",
    "print(\"Making predictions on autograder data...\")\n",
    "predictions_autograder = final_model.predict(X_autograder_eng)\n",
    "print(f\"Predictions shape: {predictions_autograder.shape}\")\n",
    "print(f\"Prediction statistics:\")\n",
    "print(f\"  Min: {predictions_autograder.min():.4f}\")\n",
    "print(f\"  Max: {predictions_autograder.max():.4f}\")\n",
    "print(f\"  Mean: {predictions_autograder.mean():.4f}\")\n",
    "print(f\"  Std: {predictions_autograder.std():.4f}\")\n",
    "\n",
    "# Prepare submission with final estimates\n",
    "estimate_MAE_on_new_data = np.array([final_cv_mae])\n",
    "predictions_autograder_data = predictions_autograder\n",
    "\n",
    "print(f\"\\nFinal submission data:\")\n",
    "print(f\"Model used: {model_type}\")\n",
    "print(f\"Estimated MAE: {estimate_MAE_on_new_data[0]:.4f}\")\n",
    "print(f\"Number of predictions: {len(predictions_autograder_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e248406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final submission file\n",
    "result = np.append(estimate_MAE_on_new_data, predictions_autograder_data)\n",
    "pd.DataFrame(result).to_csv(\"autograder_submission_pipeline2.txt\", index=False, header=False)\n",
    "\n",
    "print(\"Final submission file 'autograder_submission_pipeline2.txt' created successfully!\")\n",
    "print(f\"File contains {len(result)} values (1 MAE estimate + {len(predictions_autograder_data)} predictions)\")\n",
    "\n",
    "# Verify the submission file\n",
    "submission_check = pd.read_csv(\"autograder_submission_pipeline2.txt\", header=None)\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Submission file shape: {submission_check.shape}\")\n",
    "print(f\"First value (MAE estimate): {submission_check.iloc[0, 0]:.4f}\")\n",
    "print(f\"Last few predictions: {submission_check.tail().values.flatten()}\")\n",
    "\n",
    "# Summary of improvements made\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"PIPELINE 2 IMPROVEMENTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"‚úÖ Feature Engineering: {len(new_features)} new features created\")\n",
    "print(f\"‚úÖ Advanced Preprocessing: IterativeImputer + RobustScaler + QuantileTransformer\")\n",
    "print(f\"‚úÖ Feature Selection: Mutual information selection (15 best features)\")\n",
    "print(f\"‚úÖ Hyperparameter Tuning: GridSearchCV for all 4 models\")\n",
    "print(f\"‚úÖ Dummy Baseline: Proper baseline comparison\")\n",
    "print(f\"‚úÖ Cross-Validation: 5-fold CV for robust performance estimation\")\n",
    "print(f\"‚úÖ Training Curves: SGD convergence and learning curve analysis\")\n",
    "print(f\"‚úÖ Final Model: {model_type}\")\n",
    "print(f\"‚úÖ Final MAE Estimate: {final_cv_mae:.4f}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c4a51",
   "metadata": {},
   "source": [
    "## Pipeline 2 Analysis and Discussion\n",
    "\n",
    "### Key Differences from Basic Pipeline\n",
    "\n",
    "This advanced pipeline differs significantly from a basic approach in several ways:\n",
    "\n",
    "#### 1. **Feature Engineering**\n",
    "- **Family Structure Features**: Created `total_kids`, `has_kids`, `has_young_kids` to capture family dynamics\n",
    "- **Work-Life Balance Indicators**: `husby_per_kid`, `experience_per_kid` to understand work-family balance\n",
    "- **Insurance Coverage Combinations**: `insurance_coverage` aggregates different insurance types\n",
    "- **Ordinal Encoding**: `education_encoded` and `region_economic` provide meaningful numerical representations\n",
    "- **Interaction Features**: `experience_education`, `husby_education` capture multiplicative relationships\n",
    "\n",
    "#### 2. **Advanced Preprocessing**\n",
    "- **IterativeImputer**: Uses sophisticated multivariate imputation instead of simple mean/median\n",
    "- **OneHotEncoder**: Robust categorical encoding with unknown category handling\n",
    "- **RobustScaler**: More resistant to outliers than StandardScaler (uses median and IQR)\n",
    "- **QuantileTransformer**: Maps features to normal distribution, helping with non-linear relationships\n",
    "\n",
    "#### 3. **Feature Selection**\n",
    "- **Mutual Information**: Uses mutual information regression to select the most informative features\n",
    "- **Dimensionality Reduction**: Reduces from 22 features to 15 most important ones\n",
    "\n",
    "#### 4. **Hyperparameter Tuning**\n",
    "- **GridSearchCV**: Systematic search across parameter spaces for all 4 models\n",
    "- **Logarithmic Scales**: Proper parameter ranges for parameters that vary widely\n",
    "- **Cross-Validation**: 3-fold CV during tuning for robust parameter selection\n",
    "\n",
    "#### 5. **Model Evaluation**\n",
    "- **Dummy Regressor Baseline**: Proper sanity check against simple rules of thumb\n",
    "- **Learning Curves**: Visualization of model performance vs training set size\n",
    "- **SGD Convergence**: Analysis of SGD convergence behavior\n",
    "- **Performance Comparison**: Before vs after tuning analysis\n",
    "\n",
    "### How This Pipeline Works\n",
    "\n",
    "1. **Feature Engineering Phase**: Creates domain-specific features that capture relationships between variables\n",
    "2. **Preprocessing Phase**: Handles missing values and scales features using robust methods\n",
    "3. **Encoding Phase**: Uses OneHotEncoder for categorical variables with unknown category handling\n",
    "4. **Transformation Phase**: Applies quantile transformation to normalize distributions\n",
    "5. **Selection Phase**: Selects the most informative features using mutual information\n",
    "6. **Tuning Phase**: Systematic hyperparameter optimization for all models\n",
    "7. **Evaluation Phase**: Comprehensive evaluation with baselines and learning curves\n",
    "8. **Final Selection**: Chooses best model based on performance\n",
    "\n",
    "### Expected Benefits\n",
    "\n",
    "- **Better Feature Representation**: Engineered features capture domain knowledge\n",
    "- **Robust to Outliers**: RobustScaler handles extreme values better\n",
    "- **Systematic Optimization**: GridSearchCV finds optimal hyperparameters\n",
    "- **Sophisticated Imputation**: IterativeImputer considers relationships between features\n",
    "- **Dimensionality Reduction**: Feature selection reduces overfitting risk\n",
    "- **Comprehensive Evaluation**: Multiple evaluation methods ensure model quality\n",
    "- **Baseline Comparison**: Dummy regressor provides sanity check\n",
    "\n",
    "This pipeline should perform significantly better than a basic approach, especially in handling the complexity and relationships present in the health insurance dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108b05c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49434975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
