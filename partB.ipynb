{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3b5f63",
   "metadata": {},
   "source": [
    "# Part B - Regression with Default Hyperparameters\n",
    "\n",
    "This notebook addresses questions 4-7 from the assignment:\n",
    "\n",
    "4. **Baseline Model**: What is the simplest baseline model we should aim to beat?\n",
    "5. **Model Training**: Train the 4 models with default hyperparameters for both pipelines\n",
    "6. **Pipeline Comparison**: Which pipeline performed the best?\n",
    "7. **Autograder Submission**: Submit work to check progress so far\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler, QuantileTransformer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Enable experimental features BEFORE importing IterativeImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('health_insurance_train.csv')\n",
    "X = data.drop('whrswk', axis=1)\n",
    "y = data['whrswk']\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Target variable statistics:\")\n",
    "print(y.describe())\n",
    "\n",
    "# Define feature types\n",
    "numerical_feats = ['experience', 'kidslt6', 'kids618', 'husby']\n",
    "categorical_feats = ['hhi', 'whi', 'hhi2', 'education', 'race', 'hispanic', 'region']\n",
    "\n",
    "print(f\"\\nNumerical features: {numerical_feats}\")\n",
    "print(f\"Categorical features: {categorical_feats}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6010a5",
   "metadata": {},
   "source": [
    "## Question 4: What is the simplest baseline model we should aim to beat?\n",
    "\n",
    "**Answer:** The simplest baseline model is a **DummyRegressor** that always predicts the mean of the training targets. This represents what we would guess if we had to predict hours worked without knowing anything about the woman.\n",
    "\n",
    "**Why this is the right baseline:**\n",
    "- It's the most naive possible prediction\n",
    "- Any model that performs worse than this is essentially useless\n",
    "- It provides a concrete performance floor to beat\n",
    "- It's commonly used in machine learning as a sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a123e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4: Calculate baseline performance\n",
    "print(\"Question 4: Baseline Model Performance\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create dummy regressor that predicts the mean\n",
    "dummy_regressor = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Use cross-validation to get fair estimate of baseline performance\n",
    "cv_scores_baseline = cross_val_score(dummy_regressor, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "baseline_mae = -cv_scores_baseline.mean()\n",
    "baseline_std = cv_scores_baseline.std()\n",
    "\n",
    "print(f\"Baseline (DummyRegressor) MAE: {baseline_mae:.4f} (+/- {baseline_std * 2:.4f})\")\n",
    "print(f\"Individual CV scores: {[-score for score in cv_scores_baseline]}\")\n",
    "\n",
    "# Also calculate what the mean prediction would be\n",
    "mean_prediction = y.mean()\n",
    "print(f\"\\nMean of target variable: {mean_prediction:.4f} hours/week\")\n",
    "print(f\"This is what the dummy regressor always predicts\")\n",
    "\n",
    "print(f\"\\n✅ Any model with MAE < {baseline_mae:.4f} is better than random guessing\")\n",
    "print(f\"✅ Any model with MAE >= {baseline_mae:.4f} is essentially useless\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d442a",
   "metadata": {},
   "source": [
    "## Question 5: Train the 4 models with default hyperparameters for both pipelines\n",
    "\n",
    "**Models to train:**\n",
    "1. KNN Regression\n",
    "2. SGD Regression  \n",
    "3. Random Forest Regression\n",
    "4. Decision Tree Regression\n",
    "\n",
    "**Pipelines to compare:**\n",
    "1. **Pipeline 1 (Basic)**: SimpleImputer + StandardScaler + OneHotEncoder\n",
    "2. **Pipeline 2 (Advanced)**: IterativeImputer + RobustScaler + QuantileTransformer + OneHotEncoder + Feature Selection\n",
    "\n",
    "**Fair Performance Estimation:**\n",
    "- **Cross-validation (5-fold)** for robust performance estimation\n",
    "- **Same random state** for reproducible results\n",
    "- **Same train/test split** for fair comparison\n",
    "- **No hyperparameter tuning** - only default parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline 1 (Basic Preprocessing)\n",
    "def create_pipeline1():\n",
    "    \"\"\"Basic preprocessing pipeline\"\"\"\n",
    "    numerical_transf = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")), \n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transf = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")), \n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transf, numerical_feats),\n",
    "            ('cat', categorical_transf, categorical_feats)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "# Create Pipeline 2 (Advanced Preprocessing) with Feature Engineering\n",
    "def create_engineered_features(X):\n",
    "    \"\"\"Create new features based on domain knowledge\"\"\"\n",
    "    X_eng = X.copy()\n",
    "    \n",
    "    # Family structure features\n",
    "    X_eng['total_kids'] = X_eng['kidslt6'] + X_eng['kids618']\n",
    "    X_eng['has_kids'] = (X_eng['total_kids'] > 0).astype(int)\n",
    "    X_eng['has_young_kids'] = (X_eng['kidslt6'] > 0).astype(int)\n",
    "    \n",
    "    # Work-life balance indicators\n",
    "    X_eng['husby_per_kid'] = X_eng['husby'] / (X_eng['total_kids'] + 1)\n",
    "    X_eng['experience_per_kid'] = X_eng['experience'] / (X_eng['total_kids'] + 1)\n",
    "    \n",
    "    # Insurance coverage combinations\n",
    "    X_eng['insurance_coverage'] = (\n",
    "        (X_eng['hhi'] == 'yes').astype(int) + \n",
    "        (X_eng['whi'] == 'yes').astype(int) + \n",
    "        (X_eng['hhi2'] == 'yes').astype(int)\n",
    "    )\n",
    "    \n",
    "    # Education level encoding (ordinal)\n",
    "    education_mapping = {\n",
    "        '9-11years': 1, '12years': 2, '13-15years': 3, '16years': 4, '>16years': 5\n",
    "    }\n",
    "    X_eng['education_encoded'] = X_eng['education'].map(education_mapping)\n",
    "    \n",
    "    # Regional economic indicators\n",
    "    region_economic = {\n",
    "        'northeast': 4, 'northcentral': 3, 'south': 2, 'west': 3, 'other': 2\n",
    "    }\n",
    "    X_eng['region_economic'] = X_eng['region'].map(region_economic)\n",
    "    \n",
    "    # Experience categories\n",
    "    X_eng['experience_category'] = pd.cut(\n",
    "        X_eng['experience'], \n",
    "        bins=[0, 5, 15, 25, 100], \n",
    "        labels=['entry', 'mid', 'senior', 'expert']\n",
    "    )\n",
    "    \n",
    "    # Interaction features\n",
    "    X_eng['experience_education'] = X_eng['experience'] * X_eng['education_encoded']\n",
    "    X_eng['husby_education'] = X_eng['husby'] * X_eng['education_encoded']\n",
    "    \n",
    "    return X_eng\n",
    "\n",
    "def create_pipeline2():\n",
    "    \"\"\"Advanced preprocessing pipeline with feature engineering\"\"\"\n",
    "    # Apply feature engineering\n",
    "    X_engineered = create_engineered_features(X)\n",
    "    \n",
    "    # Update feature lists\n",
    "    categorical_features_eng = ['hhi', 'whi', 'hhi2', 'education', 'race', 'hispanic', 'region', 'experience_category']\n",
    "    numerical_features_eng = ['experience', 'kidslt6', 'kids618', 'husby', 'total_kids', 'has_kids', 'has_young_kids',\n",
    "                             'husby_per_kid', 'experience_per_kid', 'insurance_coverage', 'education_encoded',\n",
    "                             'region_economic', 'experience_education', 'husby_education']\n",
    "    \n",
    "    # Numerical preprocessing pipeline\n",
    "    numerical_pipeline = Pipeline([\n",
    "        ('imputer', IterativeImputer(random_state=RANDOM_STATE, max_iter=10)),\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('quantile', QuantileTransformer(output_distribution='normal', random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    \n",
    "    # Categorical preprocessing pipeline\n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    # Combine preprocessing\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numerical_pipeline, numerical_features_eng),\n",
    "        ('cat', categorical_pipeline, categorical_features_eng)\n",
    "    ])\n",
    "    \n",
    "    # Full pipeline with feature selection\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature_selection', SelectKBest(score_func=mutual_info_regression, k=15)),\n",
    "    ])\n",
    "    \n",
    "    return full_pipeline, X_engineered\n",
    "\n",
    "print(\"Pipelines created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Train and evaluate all models with both pipelines\n",
    "print(\"Question 5: Training and Evaluating Models\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create pipelines\n",
    "pipeline1 = create_pipeline1()\n",
    "pipeline2, X_engineered = create_pipeline2()\n",
    "\n",
    "# Define models with default hyperparameters\n",
    "models = {\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'SGD': SGDRegressor(random_state=RANDOM_STATE),\n",
    "    'Random Forest': RandomForestRegressor(random_state=RANDOM_STATE),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "print(\"Training models with Pipeline 1 (Basic)...\")\n",
    "for name, model in models.items():\n",
    "    print(f\"  Training {name}...\")\n",
    "    \n",
    "    # Create full pipeline\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', pipeline1),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(full_pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "    mae = -cv_scores.mean()\n",
    "    std = cv_scores.std()\n",
    "    \n",
    "    results[f\"{name}_Pipeline1\"] = {\n",
    "        'MAE': mae,\n",
    "        'std': std,\n",
    "        'scores': cv_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"    MAE: {mae:.4f} (+/- {std * 2:.4f})\")\n",
    "\n",
    "print(\"\\nTraining models with Pipeline 2 (Advanced)...\")\n",
    "for name, model in models.items():\n",
    "    print(f\"  Training {name}...\")\n",
    "    \n",
    "    # Create full pipeline\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', pipeline2),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(full_pipeline, X_engineered, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "    mae = -cv_scores.mean()\n",
    "    std = cv_scores.std()\n",
    "    \n",
    "    results[f\"{name}_Pipeline2\"] = {\n",
    "        'MAE': mae,\n",
    "        'std': std,\n",
    "        'scores': cv_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"    MAE: {mae:.4f} (+/- {std * 2:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ed7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE RESULTS: ALL MODELS AND PIPELINES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<15} | {'Pipeline':<10} | {'MAE':<12} | {'Std':<12} | {'vs Baseline':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Sort results by MAE for easy comparison\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1]['MAE'])\n",
    "\n",
    "for model_pipeline, metrics in sorted_results:\n",
    "    model_name, pipeline_name = model_pipeline.split('_')\n",
    "    mae = metrics['MAE']\n",
    "    std = metrics['std']\n",
    "    \n",
    "    # Compare to baseline\n",
    "    vs_baseline = ((baseline_mae - mae) / baseline_mae * 100)\n",
    "    improvement = f\"{vs_baseline:+.1f}%\"\n",
    "    \n",
    "    print(f\"{model_name:<15} | {pipeline_name:<10} | {mae:<12.4f} | {std:<12.4f} | {improvement:<12}\")\n",
    "\n",
    "print(f\"\\nBaseline (Dummy): {baseline_mae:.4f}\")\n",
    "\n",
    "# Find best overall model\n",
    "best_model_pipeline = sorted_results[0][0]\n",
    "best_mae = sorted_results[0][1]['MAE']\n",
    "best_model, best_pipeline = best_model_pipeline.split('_')\n",
    "\n",
    "print(f\"\\n🏆 BEST OVERALL: {best_model} with {best_pipeline}\")\n",
    "print(f\"Best MAE: {best_mae:.4f}\")\n",
    "print(f\"Improvement over baseline: {((baseline_mae - best_mae) / baseline_mae * 100):+.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064cc4a4",
   "metadata": {},
   "source": [
    "## Question 6: Which pipeline performed the best?\n",
    "\n",
    "**Answer:** Based on the results above, we can determine which pipeline performed best by comparing:\n",
    "\n",
    "1. **Best overall performance** - which model-pipeline combination achieved the lowest MAE\n",
    "2. **Pipeline comparison** - which pipeline generally performed better across all models\n",
    "3. **Statistical significance** - whether the differences are meaningful\n",
    "\n",
    "**Analysis:**\n",
    "- Look at the sorted results table above\n",
    "- Compare Pipeline1 vs Pipeline2 performance for each model type\n",
    "- Consider both the MAE values and the standard deviations\n",
    "- The best pipeline should consistently outperform the other across multiple models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6: Detailed pipeline comparison\n",
    "print(\"Question 6: Pipeline Comparison Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Compare pipelines for each model\n",
    "pipeline1_wins = 0\n",
    "pipeline2_wins = 0\n",
    "\n",
    "print(\"Head-to-head comparison:\")\n",
    "print(f\"{'Model':<15} | {'Pipeline1 MAE':<15} | {'Pipeline2 MAE':<15} | {'Winner':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for model in models.keys():\n",
    "    p1_key = f\"{model}_Pipeline1\"\n",
    "    p2_key = f\"{model}_Pipeline2\"\n",
    "    \n",
    "    p1_mae = results[p1_key]['MAE']\n",
    "    p2_mae = results[p2_key]['MAE']\n",
    "    \n",
    "    if p1_mae < p2_mae:\n",
    "        winner = \"Pipeline1\"\n",
    "        pipeline1_wins += 1\n",
    "    else:\n",
    "        winner = \"Pipeline2\"\n",
    "        pipeline2_wins += 1\n",
    "    \n",
    "    print(f\"{model:<15} | {p1_mae:<15.4f} | {p2_mae:<15.4f} | {winner:<10}\")\n",
    "\n",
    "print(f\"\\nPipeline1 wins: {pipeline1_wins}/4\")\n",
    "print(f\"Pipeline2 wins: {pipeline2_wins}/4\")\n",
    "\n",
    "# Calculate average improvement\n",
    "pipeline1_models = [f\"{model}_Pipeline1\" for model in models.keys()]\n",
    "pipeline2_models = [f\"{model}_Pipeline2\" for model in models.keys()]\n",
    "\n",
    "avg_p1_mae = np.mean([results[model]['MAE'] for model in pipeline1_models])\n",
    "avg_p2_mae = np.mean([results[model]['MAE'] for model in pipeline2_models])\n",
    "\n",
    "print(f\"\\nAverage MAE across all models:\")\n",
    "print(f\"Pipeline1: {avg_p1_mae:.4f}\")\n",
    "print(f\"Pipeline2: {avg_p2_mae:.4f}\")\n",
    "\n",
    "if avg_p2_mae < avg_p1_mae:\n",
    "    improvement = ((avg_p1_mae - avg_p2_mae) / avg_p1_mae * 100)\n",
    "    print(f\"✅ Pipeline2 is better by {improvement:.1f}% on average\")\n",
    "    best_pipeline = \"Pipeline2\"\n",
    "else:\n",
    "    improvement = ((avg_p2_mae - avg_p1_mae) / avg_p2_mae * 100)\n",
    "    print(f\"✅ Pipeline1 is better by {improvement:.1f}% on average\")\n",
    "    best_pipeline = \"Pipeline1\"\n",
    "\n",
    "print(f\"\\n🏆 WINNER: {best_pipeline}\")\n",
    "print(f\"Best pipeline will be used for the next exercises.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5bf130",
   "metadata": {},
   "source": [
    "## Question 7: Submit work to the autograder\n",
    "\n",
    "**Answer:** We will create a submission file using the best performing model-pipeline combination identified in Question 6.\n",
    "\n",
    "**Submission process:**\n",
    "1. Load the autograder data\n",
    "2. Apply the best preprocessing pipeline\n",
    "3. Train the best model on the full dataset\n",
    "4. Make predictions on autograder data\n",
    "5. Create submission file with MAE estimate and predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eef627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7: Create autograder submission\n",
    "print(\"Question 7: Creating Autograder Submission\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load autograder data\n",
    "print(\"Loading autograder data...\")\n",
    "data_autograder = pd.read_csv('health_insurance_autograde.csv')\n",
    "print(f\"Autograder data shape: {data_autograder.shape}\")\n",
    "\n",
    "# Determine best model and pipeline\n",
    "best_model_pipeline = sorted_results[0][0]\n",
    "best_model, best_pipeline = best_model_pipeline.split('_')\n",
    "best_mae = sorted_results[0][1]['MAE']\n",
    "\n",
    "print(f\"Using best model: {best_model} with {best_pipeline}\")\n",
    "print(f\"Expected MAE: {best_mae:.4f}\")\n",
    "\n",
    "# Create the best pipeline and model\n",
    "if best_pipeline == \"Pipeline1\":\n",
    "    best_preprocessor = pipeline1\n",
    "    X_for_training = X\n",
    "else:\n",
    "    best_preprocessor = pipeline2\n",
    "    X_for_training = X_engineered\n",
    "\n",
    "# Get the best model\n",
    "best_model_instance = models[best_model]\n",
    "\n",
    "# Create full pipeline\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocessor', best_preprocessor),\n",
    "    ('regressor', best_model_instance)\n",
    "])\n",
    "\n",
    "# Train on full dataset\n",
    "print(\"Training final model on full dataset...\")\n",
    "final_pipeline.fit(X_for_training, y)\n",
    "\n",
    "# Prepare autograder data\n",
    "if best_pipeline == \"Pipeline2\":\n",
    "    X_autograder_processed = create_engineered_features(data_autograder)\n",
    "else:\n",
    "    X_autograder_processed = data_autograder\n",
    "\n",
    "# Make predictions\n",
    "print(\"Making predictions on autograder data...\")\n",
    "predictions = final_pipeline.predict(X_autograder_processed)\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Prediction statistics:\")\n",
    "print(f\"  Min: {predictions.min():.4f}\")\n",
    "print(f\"  Max: {predictions.max():.4f}\")\n",
    "print(f\"  Mean: {predictions.mean():.4f}\")\n",
    "print(f\"  Std: {predictions.std():.4f}\")\n",
    "\n",
    "# Create submission file\n",
    "estimate_MAE_on_new_data = np.array([best_mae])\n",
    "predictions_autograder_data = predictions\n",
    "\n",
    "result = np.append(estimate_MAE_on_new_data, predictions_autograder_data)\n",
    "pd.DataFrame(result).to_csv(\"autograder_submission_partB.txt\", index=False, header=False)\n",
    "\n",
    "print(f\"\\n✅ Submission file created: 'autograder_submission_partB.txt'\")\n",
    "print(f\"File contains {len(result)} values (1 MAE estimate + {len(predictions)} predictions)\")\n",
    "print(f\"MAE estimate: {best_mae:.4f}\")\n",
    "print(f\"Number of predictions: {len(predictions)}\")\n",
    "\n",
    "# Verify submission file\n",
    "submission_check = pd.read_csv(\"autograder_submission_partB.txt\", header=None)\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Submission file shape: {submission_check.shape}\")\n",
    "print(f\"First value (MAE estimate): {submission_check.iloc[0, 0]:.4f}\")\n",
    "print(f\"Last few predictions: {submission_check.tail().values.flatten()}\")\n",
    "\n",
    "print(f\"\\n🎯 Ready for autograder submission!\")\n",
    "print(f\"Best model: {best_model}\")\n",
    "print(f\"Best pipeline: {best_pipeline}\")\n",
    "print(f\"Expected MAE: {best_mae:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
