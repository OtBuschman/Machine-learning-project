{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aca7097",
   "metadata": {},
   "source": [
    "# Pipeline 1: Basic Preprocessing Pipeline\n",
    "\n",
    "This notebook implements the first preprocessing pipeline with basic preprocessing techniques:\n",
    "1. **Simple Imputation**: Using median for numerical and most frequent for categorical features\n",
    "2. **Standard Scaling**: Using StandardScaler for numerical features\n",
    "3. **One-Hot Encoding**: Using OneHotEncoder for categorical features\n",
    "4. **Basic Pipeline**: Simple but effective preprocessing approach\n",
    "\n",
    "## Motivation\n",
    "\n",
    "This pipeline serves as a baseline approach that:\n",
    "- Uses straightforward preprocessing techniques\n",
    "- Provides a foundation for comparison with more advanced methods\n",
    "- Demonstrates basic data preparation for machine learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524bc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab882e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are your training samples along with their labels\n",
    "data = pd.read_csv('health_insurance_train.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we separate target (y) and features (X)\n",
    "X = data.drop('whrswk', axis=1)\n",
    "y = data['whrswk']\n",
    "# divide columns into numerical and non-numerical features\n",
    "numerical_feats = ['experience', 'kidslt6', 'kids618', 'husby']\n",
    "categorical_feats = ['hhi', 'whi', 'hhi2', 'education', 'race', 'hispanic', 'region']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5191d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer for numbers\n",
    "numerical_transf = Pipeline(steps=[('imputer', SimpleImputer(strategy=\"median\")), ('scaler', StandardScaler())])\n",
    "# transformer for non-numbers\n",
    "categorical_transf = Pipeline(steps=[('imputer', SimpleImputer(strategy=\"most_frequent\")), ('encoder', OneHotEncoder())])\n",
    "#\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transf, numerical_feats),\n",
    "        ('cat', categorical_transf, categorical_feats)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1dea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(X)\n",
    "\n",
    "X_transformed = preprocessor.transform(X)\n",
    "\n",
    "print(X_transformed[0])\n",
    "# You need to extract the features and the regression target. The regression target is 'whrswk'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003523b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autograder \n",
    "\n",
    "In the autograder you will need to provide two things: 1) estimate of the MAE of your model on unseen data, 2) the predictions on the autograder data. For the autograder data we only provide the features and not the regression targets. Thus, you cannot compute the MAE on this data yourself - you need to estimate that with the data provided above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad86f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_autograder = pd.read_csv('health_insurance_autograde.csv')\n",
    "data_autograder.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40212693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Replace this with your own estimate of the MAE of your best model\n",
    "estimate_MAE_on_new_data = np.array([1.0])\n",
    "\n",
    "# TODO Replace this with the predictions of your best model\n",
    "# via e.g. prediction = model.predict(data_autograder)\n",
    "predictions_autograder_data = np.array([-1] * 17272)\n",
    "\n",
    "# Upload this file to the Vocareum autograder:\n",
    "result = np.append(estimate_MAE_on_new_data, predictions_autograder_data)\n",
    "pd.DataFrame(result).to_csv(\"autograder_submission.txt\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9225bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b3e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91516191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac739cfb",
   "metadata": {},
   "source": [
    "## Pipeline 1 Analysis and Discussion\n",
    "\n",
    "### Basic Preprocessing Approach\n",
    "\n",
    "This pipeline implements a straightforward preprocessing approach that serves as a baseline for comparison:\n",
    "\n",
    "#### 1. **Simple Imputation**\n",
    "- **Numerical features**: Uses median imputation (robust to outliers)\n",
    "- **Categorical features**: Uses most frequent value imputation\n",
    "- **Advantage**: Simple and fast\n",
    "- **Limitation**: Doesn't consider relationships between features\n",
    "\n",
    "#### 2. **Standard Scaling**\n",
    "- **Method**: StandardScaler (mean=0, std=1)\n",
    "- **Purpose**: Ensures all numerical features are on the same scale\n",
    "- **Advantage**: Works well with most ML algorithms\n",
    "- **Limitation**: Sensitive to outliers\n",
    "\n",
    "#### 3. **One-Hot Encoding**\n",
    "- **Method**: OneHotEncoder for categorical variables\n",
    "- **Purpose**: Converts categorical data to numerical format\n",
    "- **Advantage**: Preserves all categorical information\n",
    "- **Limitation**: Can create high-dimensional feature space\n",
    "\n",
    "### Pipeline Characteristics\n",
    "\n",
    "- **Simplicity**: Easy to understand and implement\n",
    "- **Speed**: Fast preprocessing and training\n",
    "- **Reliability**: Well-established techniques with predictable behavior\n",
    "- **Baseline**: Provides a solid foundation for comparison\n",
    "\n",
    "### Expected Performance\n",
    "\n",
    "This basic pipeline should provide reasonable performance but may be limited by:\n",
    "- Simple imputation strategies\n",
    "- Standard scaling sensitivity to outliers\n",
    "- High-dimensional categorical encoding\n",
    "- No feature engineering or selection\n",
    "\n",
    "The pipeline serves as an excellent baseline to demonstrate the value of more advanced preprocessing techniques in Pipeline 2.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
